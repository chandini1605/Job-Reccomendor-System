{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78adfcb7-4611-4837-b7d3-c8983ebd83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 1. Install dependencies\n",
    "# ========================\n",
    "%pip install -q sentence-transformers scikit-learn pandas numpy faiss-cpu joblib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9c958e-7c7d-46e7-8e24-d6cc5be61af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea1cf3-56c2-4ae0-8ff9-0b3c7577446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (1.12.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chandini\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Dataset shape: (962, 2)\n",
      "       Category                                             Resume\n",
      "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
      "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
      "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
      "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
      "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
      "\n",
      "Classifier Report:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         3\n",
      "                     Arts       1.00      1.00      1.00         6\n",
      "       Automation Testing       1.00      1.00      1.00         5\n",
      "               Blockchain       1.00      1.00      1.00         7\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         9\n",
      "             Data Science       1.00      1.00      1.00         5\n",
      "                 Database       1.00      1.00      1.00         8\n",
      "          DevOps Engineer       1.00      0.93      0.96        14\n",
      "         DotNet Developer       1.00      1.00      1.00         5\n",
      "            ETL Developer       1.00      1.00      1.00         7\n",
      "   Electrical Engineering       1.00      1.00      1.00         6\n",
      "                       HR       1.00      1.00      1.00        12\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         7\n",
      "           Java Developer       1.00      1.00      1.00        15\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "Network Security Engineer       1.00      1.00      1.00         3\n",
      "       Operations Manager       1.00      1.00      1.00        12\n",
      "                      PMO       0.88      1.00      0.93         7\n",
      "         Python Developer       1.00      1.00      1.00        10\n",
      "            SAP Developer       1.00      1.00      1.00         7\n",
      "                    Sales       1.00      1.00      1.00         8\n",
      "                  Testing       1.00      1.00      1.00        16\n",
      "            Web Designing       1.00      1.00      1.00         5\n",
      "\n",
      "                 accuracy                           0.99       193\n",
      "                macro avg       0.99      1.00      1.00       193\n",
      "             weighted avg       1.00      0.99      0.99       193\n",
      "\n",
      "FAISS index size: 962\n",
      "\n",
      "Top recommended roles with percentages:\n",
      "Python Developer - 59.5% match\n",
      "Java Developer - 20.88% match\n",
      "Data Science - 19.62% match\n",
      "✅ Model and components saved as recommender_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# Job Role Recommender System\n",
    "# ===============================\n",
    "\n",
    "# 1. Install required libraries\n",
    "%pip install pandas scikit-learn faiss-cpu joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Imports\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load dataset\n",
    "# -------------------------------\n",
    "# Update path to your dataset file\n",
    "df = pd.read_csv(r\"D:\\project\\UpdatedResumeDataSet.csv\")  \n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Preprocessing\n",
    "# -------------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"cleaned\"] = df[\"Resume\"].apply(clean_text)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Encode target labels\n",
    "# -------------------------------\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"Category\"])\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Train-test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"cleaned\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Vectorization\n",
    "# -------------------------------\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Train classifier\n",
    "# -------------------------------\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(\"\\nClassifier Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# -------------------------------\n",
    "# 9. FAISS Index\n",
    "# -------------------------------\n",
    "X_vec_all = vectorizer.transform(df[\"cleaned\"])\n",
    "X_faiss = X_vec_all.astype('float32').toarray()\n",
    "\n",
    "d = X_faiss.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(X_faiss)\n",
    "\n",
    "print(\"FAISS index size:\", index.ntotal)\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Build job skills dictionary\n",
    "# -------------------------------\n",
    "job_skills_dict = {}\n",
    "for role in df[\"Category\"].unique():\n",
    "    role_texts = df[df[\"Category\"] == role][\"cleaned\"]\n",
    "    words = \" \".join(role_texts).split()\n",
    "    top_words = pd.Series(words).value_counts().head(50).index.tolist()\n",
    "    job_skills_dict[role] = top_words\n",
    "\n",
    "# -------------------------------\n",
    "# 11. Recommend function\n",
    "# -------------------------------\n",
    "def recommend_roles(resume_text, model, vectorizer, index, job_labels, job_skills_dict, top_n=3):\n",
    "    vec = vectorizer.transform([resume_text])\n",
    "    probs = model.predict_proba(vec)[0]\n",
    "\n",
    "    query_vec = vec.astype('float32').toarray()\n",
    "    D, I = index.search(query_vec, k=top_n*2)\n",
    "\n",
    "    results = []\n",
    "    for i, role in enumerate(job_labels):\n",
    "        classifier_prob = probs[i]\n",
    "\n",
    "        similarity_score = 0.0\n",
    "        if len(I[0]) > 0:\n",
    "            for j, idx in enumerate(I[0]):\n",
    "                if idx < len(job_labels) and job_labels[idx] == role:\n",
    "                    similarity_score = float(1 - D[0][j])\n",
    "                    break\n",
    "\n",
    "        resume_tokens = set(resume_text.lower().split())\n",
    "        role_skills = set(job_skills_dict.get(role, []))\n",
    "        skill_overlap = len(resume_tokens & role_skills) / max(1, len(role_skills))\n",
    "\n",
    "        combined_score = 0.5 * classifier_prob + 0.3 * similarity_score + 0.2 * skill_overlap\n",
    "\n",
    "        results.append({\n",
    "            \"role\": role,\n",
    "            \"classifier_score\": classifier_prob,\n",
    "            \"similarity_score\": similarity_score,\n",
    "            \"skill_overlap\": skill_overlap,\n",
    "            \"combined_score\": combined_score\n",
    "        })\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x['combined_score'], reverse=True)[:top_n]\n",
    "\n",
    "    # Normalize scores so top_n add up to 100%\n",
    "    total_score = sum(r[\"combined_score\"] for r in sorted_results)\n",
    "    for r in sorted_results:\n",
    "        r[\"percentage\"] = round((r[\"combined_score\"] / total_score) * 100, 2) if total_score > 0 else 0\n",
    "\n",
    "    return sorted_results\n",
    "\n",
    "# -------------------------------\n",
    "# 12. Test the recommender\n",
    "# -------------------------------\n",
    "job_labels = list(le.classes_)\n",
    "\n",
    "resume_example = \"Experienced Python developer with Django, Flask, REST APIs, PostgreSQL, AWS, and Docker.\"\n",
    "top_roles = recommend_roles(resume_example, clf, vectorizer, index, job_labels, job_skills_dict, top_n=3)\n",
    "\n",
    "print(\"\\nTop recommended roles with percentages:\")\n",
    "for r in top_roles:\n",
    "    print(f\"{r['role']} - {r['percentage']}% match\")\n",
    "\n",
    "# -------------------------------\n",
    "# 13. Save models for deployment\n",
    "# -------------------------------\n",
    "# Save with joblib (optional)\n",
    "joblib.dump(clf, \"jobrole_classifier.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "faiss.write_index(index, \"faiss_index.idx\")\n",
    "\n",
    "# Save as a single pickle file for Flask\n",
    "model_data = {\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"model\": clf,\n",
    "    \"job_labels\": job_labels,\n",
    "    \"faiss_index\": index,\n",
    "    \"job_skills_dict\": job_skills_dict\n",
    "}\n",
    "\n",
    "with open(\"recommender_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✅ Model and components saved as recommender_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5338077-7017-49f6-b19c-be4ada4ff4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as recommender_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model, vectorizer and job labels\n",
    "model_data = {\n",
    "    \"vectorizer\": vectorizer,   # your TF-IDF vectorizer\n",
    "    \"model\": clf,               # your trained classifier\n",
    "    \"job_labels\": job_labels    # list of job categories\n",
    "}\n",
    "\n",
    "with open(\"recommender_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✅ Model saved as recommender_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea7818-de79-4bb3-b15a-30df3f2573b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a634df-3840-4ac0-ba92-fef0b078ee67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
